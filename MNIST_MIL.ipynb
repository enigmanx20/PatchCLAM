{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af797dd-3ecd-4f06-b43a-8811cc681e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mil_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae77da-fd25-4834-a134-d0d8eff9dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"enable_clam_training\": True, # when False, instance classifier is never trained. k_sample and subtyping options are not used.  \n",
    "    \"model_config\": mil_configs.clam_config,\n",
    "    #\"model_config\": mil_configs.abmil_config,\n",
    "    #\"model_config\": mil_configs.sdp_config,\n",
    "    #\"model_config\": mil_configs.avg_config,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabc15d-b14e-478a-8e66-28d4c96b2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 6, 8, 9 classification\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "from utils import MILMNISTDataset, calc_acc, resnet50_baseline\n",
    "from models import ClamWrapper\n",
    "\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MILMNISTDataset(root='.', target_digits=[6, 8, 9], bag_size=64, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=1, shuffle=False, num_workers=0)\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MILMNISTDataset(root='.', target_digits=[6, 8, 9], bag_size=64, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ClamWrapper(train_config['model_config'], base_encoder=resnet50_baseline(pretrained=True)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config['lr'])\n",
    "scaler = GradScaler()\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "inst_criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "#calc_acc(model, test_loader, device)\n",
    "\n",
    "itr = 0\n",
    "for images, labels in tqdm.tqdm(train_loader):\n",
    "    itr+=1\n",
    "    model.train()\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with autocast(device_type='cuda', dtype=torch.float16):\n",
    "        if train_config['enable_clam_training']:\n",
    "            bag_logit, inst_logit, top_p_ids, top_n_ids  = model(images)\n",
    "            bag_loss = criterion(bag_logit, labels)\n",
    "            instance_target = torch.zeros_like(inst_logit).to(inst_logit.device)\n",
    "            instance_mask   = torch.zeros_like(inst_logit).to(inst_logit.device)\n",
    "            for p_index, n_index in zip(top_p_ids, top_n_ids):\n",
    "                if p_index.dim() > 1: # CLAM-MB\n",
    "                    instance_target[p_index[labels.item()], labels] = 1.\n",
    "                    if train_config['model_config']['subtyping']:\n",
    "                        instance_mask[p_index[labels.item()], :] = 1. \n",
    "                    else:\n",
    "                        instance_mask[p_index[labels.item(), :], labels] = 1. \n",
    "                    instance_mask[n_index[labels.item()], labels] = 1.\n",
    "                else: # CLAM-SB\n",
    "                    instance_target[p_index, labels] = 1.\n",
    "                    if train_config['model_config']['subtyping']:\n",
    "                        instance_mask[p_index] = 1.         \n",
    "                    else:\n",
    "                        instance_mask[p_index, labels] = 1. \n",
    "                    \n",
    "                    instance_mask[n_index, labels] = 1.\n",
    "            inst_loss = inst_criterion(inst_logit.view(-1), instance_target.view(-1)) * instance_mask.view(-1)\n",
    "            inst_loss = inst_loss.mean()\n",
    "        \n",
    "            loss = 0.7*bag_loss + 0.3*inst_loss\n",
    "        else:\n",
    "            bag_logit = model.eval_forward(images)\n",
    "            loss = criterion(bag_logit, labels)\n",
    "    \n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    if itr%500==0:\n",
    "        print(f'{itr} iterations')\n",
    "        calc_acc(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0da7d5-1966-45ef-b8d0-3029ba07fd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
